# BirdNET V2.4 — Model Reference

Техническая документация по работе с моделями BirdNET V2.4 в проекте Bird Song Analyzer.

**Модель:** BirdNET V2.4 FP16, Cornell Lab of Ornithology
**Лицензия:** CC BY-NC-SA 4.0 (некоммерческая)
**Формат:** TensorFlow Lite (FlatBuffers)

---

## 1. Файлы модели

Все файлы расположены в `app/src/main/assets/birdnet/v24/`.

| Файл | Размер | Назначение |
|------|--------|------------|
| `audio-model-fp16.tflite` | 25 MB | Аудио-классификатор (CNN по мел-спектрограмме) |
| `meta-model.tflite` | 29 MB | Географо-временной фильтр |
| `labels/en_us.txt` | ~200 KB | 6 521 меток (Scientific + English common name) |
| `labels/ru.txt` | ~200 KB | 6 522 меток (Scientific + Russian common name) |

### 1.1 Формат TFLite

TFLite-файлы — это сериализованные FlatBuffers, содержащие граф вычислений и веса нейросети. FP16 означает, что веса хранятся в формате half-precision float (16 бит), что вдвое компактнее FP32 при минимальной потере точности. На этапе инференса TFLite runtime может выполнять вычисления как в FP16, так и в FP32 (с повышением точности) в зависимости от аппаратной поддержки устройства.

Интерпретатор загружает файл через `MappedByteBuffer` (memory-mapped I/O):

```kotlin
context.assets.openFd(assetPath).use { fd ->
    FileInputStream(fd.fileDescriptor).use { fis ->
        fis.channel.map(FileChannel.MapMode.READ_ONLY, fd.startOffset, fd.declaredLength)
    }
}
```

`MappedByteBuffer` доступен только для чтения — один буфер безопасно разделяется между несколькими `Interpreter` для параллельного инференса. Каждый `Interpreter` при этом должен быть отдельным экземпляром (содержит mutable-состояние внутренних тензоров).

### 1.2 Формат меток

Текстовый файл, одна строка на класс. Формат строки:

```
ScientificName_CommonName
```

Примеры:
```
Parus major_Great Tit
Corvus corax_Common Raven
Apis mellifera_Western Honey Bee
```

Индекс строки (0-based) соответствует индексу выхода модели. Парсинг — разделение по первому символу `_`: левая часть — научное название, правая — обиходное.

Всего 6 521 класс: ~6 500 видов птиц + несколько не-птичьих категорий (Engine, Noise, Human vocal, Apis mellifera и др.).

---

## 2. Аудиомодель (audio-model-fp16.tflite)

### 2.1 Что делает

Принимает 3 секунды сырого аудио и возвращает **logits** (необработанные оценки) для каждого из 6 521 классов. Внутри модель:
1. Вычисляет мел-спектрограмму из входного PCM
2. Пропускает спектрограмму через свёрточную нейросеть (CNN)
3. Выдаёт вектор logits

### 2.2 Вход

| Параметр | Значение |
|----------|----------|
| **Shape** | `[1, 144000]` — batch=1, samples=144000 |
| **Тип** | `Float32` |
| **Sample rate** | 48 000 Hz |
| **Длительность** | 3 секунды (48000 * 3 = 144 000 сэмплов) |
| **Каналы** | Моно |
| **Диапазон значений** | `[-1.0, 1.0]` — нормализованный float PCM |

**Почему именно 48 kHz, 3 с, моно:**
- **48 kHz** — частота дискретизации, на которой обучена модель. Частоты до 24 кHz (теорема Найквиста) покрывают диапазон вокализации всех известных птиц (80 Hz — 12 kHz) с запасом
- **3 секунды** — фиксированный размер входного тензора модели. Большинство птичьих позывок и коротких песен укладываются в 1-3 секунды. Это хардкод архитектуры: передача массива другого размера вызовет ошибку
- **Моно** — стерео не несёт дополнительной информации для классификации вида

**Нормализация входа:**
```
PCM int16 → float32: sample / 32768.0
```
Результат: значения в диапазоне `[-1.0, 1.0]`.

### 2.3 Выход

| Параметр | Значение |
|----------|----------|
| **Shape** | `[1, 6521]` — batch=1, один score на каждый класс |
| **Тип** | `Float32` |
| **Диапазон** | `(-inf, +inf)` — сырые logits, НЕ вероятности |

Logits требуют преобразования через sigmoid для получения вероятностей:

```kotlin
probability = 1.0 / (1.0 + exp(-logit))
```

После sigmoid значения в диапазоне `[0.0, 1.0]`. Это **независимые вероятности** (не softmax), поэтому несколько видов могут иметь высокую вероятность одновременно — что соответствует реальности (несколько птиц поют одновременно).

### 2.4 Код инференса

```kotlin
// Подготовка тензоров
val input = arrayOf(audioChunk)                    // Array<FloatArray> [1][144000]
val output = Array(1) { FloatArray(labels.size) }  // Array<FloatArray> [1][6521]

// Запуск
audioInterpreter.run(input, output)

// Результат: output[0] — FloatArray[6521] logits
val logits = output[0]
val scores = FloatArray(logits.size) { i -> sigmoid(logits[i]) }
```

---

## 3. Мета-модель (meta-model.tflite)

### 3.1 Что делает

Фильтрует результаты аудиомодели по географическому положению и времени года. Если известны GPS-координаты и неделя года, мета-модель обнуляет виды, которые не встречаются в данной местности в данный сезон. Это резко снижает ложные срабатывания.

### 3.2 Вход

| Параметр | Значение |
|----------|----------|
| **Shape** | `[1, 3]` |
| **Тип** | `Float32` |
| **Элементы** | `[latitude, longitude, weekOfYear]` |

| Поле | Диапазон | Пример |
|------|----------|--------|
| `latitude` | -90.0 .. 90.0 | 53.9 (Минск) |
| `longitude` | -180.0 .. 180.0 | 27.5 (Минск) |
| `weekOfYear` | 1 .. 53 | 24 (середина июня) |

### 3.3 Выход

| Параметр | Значение |
|----------|----------|
| **Shape** | `[1, 6521]` — один score на каждый класс |
| **Тип** | `Float32` |
| **Диапазон** | `[0.0, 1.0]` — вероятность присутствия вида |

Значение ~1.0 означает "вид встречается здесь в это время", ~0.0 означает "вид не встречается".

### 3.4 Применение

Результат мета-модели **поэлементно умножается** на вероятности аудиомодели:

```kotlin
val metaInput = arrayOf(floatArrayOf(lat, lon, week))
val metaOutput = Array(1) { FloatArray(labels.size) }
metaInterpreter.run(metaInput, metaOutput)

for (i in scores.indices) {
    scores[i] *= metaOutput[0][i]  // element-wise multiplication
}
```

Если вид не встречается в данной местности (`metaScore ≈ 0`), его итоговая вероятность будет подавлена до ~0, независимо от того, насколько уверенно аудиомодель его распознала.

**Мета-модель опциональна.** Если GPS недоступен, инференс выполняется только по аудиомодели. Это снижает точность, но не блокирует работу.

---

## 4. Полный pipeline инференса

```
Микрофон/файл
     │
     ▼
┌──────────────────────┐
│ Декодирование PCM    │  AudioFileDecoder / AudioRecord API
│ int16 → float32      │  sample / 32768.0
│ resample → 48 kHz    │  линейная интерполяция если нужно
│ stereo → mono        │  среднее каналов
│ нарезка по 144000    │  чанки по 3 секунды, без перекрытия*
└──────────┬───────────┘
           │ FloatArray[144000], диапазон [-1, 1]
           ▼
┌──────────────────────┐
│ AudioChunkProcessor  │  (опционально, для шумоподавления)
│                      │
│ 1. RMS < 0.005?      │─── да ──→ SKIP (тишина)
│ 2. Клиппинг?         │─── да ──→ SKIP (перегруз)
│ 3. Goertzel: вне     │
│    птичьего диапазона?│─── да ──→ SKIP (шум/электроника)
│ 4. Bandpass 80-15kHz │
│ 5. Peak < 0.001?     │─── да ──→ SKIP (после фильтра тихо)
│ 6. Нормализация →0.5 │
└──────────┬───────────┘
           │ FloatArray[144000], отфильтрованный, [-1, 1]
           ▼
┌──────────────────────┐
│ Аудиомодель TFLite   │  audio-model-fp16.tflite
│ [1, 144000] → CNN    │
│ → [1, 6521] logits   │
│ → sigmoid → [0, 1]   │
└──────────┬───────────┘
           │ FloatArray[6521] вероятности
           ▼
┌──────────────────────┐
│ Мета-модель TFLite   │  meta-model.tflite (если есть GPS)
│ [1, 3] → [1, 6521]  │
│ scores *= metaScores │
└──────────┬───────────┘
           │ FloatArray[6521] скорректированные
           ▼
┌──────────────────────┐
│ Построение детекций  │
│ filter: conf >= 0.1  │
│ sort: по убыванию    │
│ take: top 10         │
└──────────┬───────────┘
           │ List<BirdDetection>
           ▼
┌──────────────────────┐
│ DetectionAggregator  │  (live-режим)
│ sliding window = 8   │
│ confirmation >= 2    │
│ threshold >= 0.5     │
└──────────┬───────────┘
           │ List<AggregatedDetection>
           ▼
        UI / БД
```

\* В `decodeChunked` по умолчанию `hopSize = chunkSize / 2` (50% перекрытие), но в benchmark-тестах используется без перекрытия.

---

## 5. Пре-процессинг: AudioChunkProcessor

Пре-процессор отсеивает чанки, которые не содержат полезного сигнала. На benchmark-данных пропускается ~11% чанков, что снижает число ложных срабатываний без потери recall.

### 5.1 Этап 1: Проверка тишины (RMS)

```
RMS = sqrt(sum(sample^2) / N)
Если RMS < 0.005 → SKIP
```

Порог 0.005 ≈ -46 dBFS. Ниже этого уровня сигнал не содержит различимой вокализации.

### 5.2 Этап 2: Проверка клиппинга

```
Если peak > 0.99 И rms > 0.3 → SKIP
```

Насыщение сигнала (клиппинг) искажает спектр и приводит к некорректной классификации. Проверяются оба условия одновременно: высокий пик + высокий RMS.

### 5.3 Этап 3: Спектральная проверка (Goertzel)

Оценка распределения энергии по 4 частотным полосам:

| Полоса | Частота | Что ловит |
|--------|---------|-----------|
| Low | 100 Hz | Моторы, ветер, сетевой гул 50/60 Hz |
| Bird-Low | 500 Hz | Голуби (~120 Hz + гармоники), совы (300-500 Hz) |
| Bird-Mid | 3000 Hz | Типичные птичьи вокализации |
| High | 12000 Hz | Электроника, насекомые |

Если > 80% энергии сосредоточено в полосе Low или High → SKIP. Алгоритм Goertzel вычисляет энергию на одной частоте за O(N) — гораздо дешевле полного FFT для 4 частот.

### 5.4 Этап 4: Полосовой фильтр (Bandpass)

Каскад двух Butterworth biquad-фильтров 2-го порядка:

| Фильтр | Тип | Частота среза | Q |
|--------|-----|--------------|---|
| High-pass | Butterworth 2nd order | 80 Hz | 1/sqrt(2) |
| Low-pass | Butterworth 2nd order | 15 000 Hz | 1/sqrt(2) |

Реализация — Direct Form II Transposed. Состояние фильтра (z1, z2) сбрасывается при каждом вызове — между чанками не переносится.

Коэффициенты вычисляются по формулам из Audio EQ Cookbook (Robert Bristow-Johnson):

```
w0 = 2 * PI * cutoff / sampleRate
alpha = sin(w0) / (2 * sqrt(2))

High-pass:                      Low-pass:
  b0 = (1 + cos(w0)) / 2         b0 = (1 - cos(w0)) / 2
  b1 = -(1 + cos(w0))            b1 = 1 - cos(w0)
  b2 = (1 + cos(w0)) / 2         b2 = (1 - cos(w0)) / 2
  a0 = 1 + alpha                 a0 = 1 + alpha
  a1 = -2 * cos(w0)              a1 = -2 * cos(w0)
  a2 = 1 - alpha                 a2 = 1 - alpha

Нормализация: все коэффициенты делятся на a0.
```

### 5.5 Этап 5: Проверка после фильтра

```
Если peak(filtered) < 0.001 → SKIP
```

Вся энергия оказалась за пределами полосы 80 Hz — 15 kHz.

### 5.6 Этап 6: Пиковая нормализация

```
Если peak в [0.001, 0.5]:
    gain = 0.5 / peak
    sample = clamp(sample * gain, -1, 1)
Если peak > 0.5:
    без изменений (сигнал достаточно громкий)
```

Цель: привести уровень сигнала к стабильному значению ~0.5 peak, чтобы модель работала в оптимальном динамическом диапазоне.

---

## 6. Построение детекций

После sigmoid и (опционально) мета-модели:

```kotlin
scores.indices
    .filter { scores[it] >= confidenceThreshold }  // >= 0.1
    .sortedByDescending { scores[it] }
    .take(topK)                                     // top 10
    .map { BirdDetection(scientificName, commonName, confidence, labelIndex) }
```

Результат — `List<BirdDetection>`:

```kotlin
data class BirdDetection(
    val scientificName: String,  // "Parus major"
    val commonName: String,      // "Great Tit"
    val confidence: Float,       // 0.0..1.0
    val labelIndex: Int,         // индекс в массиве labels (= индексу выхода модели)
)
```

---

## 7. Пороги и параметры по умолчанию

### Классификатор

| Параметр | Значение | Контекст |
|----------|----------|----------|
| `confidenceThreshold` | 0.1 | Benchmark: ловим всё для анализа |
| `confidenceThreshold` | 0.5 | Продакшн: только уверенные детекции |
| `topK` | 10 | Макс. количество видов на один чанк |
| `tfliteThreads` | 2 | Потоков TFLite на один Interpreter |

### Агрегатор (DetectionAggregator)

| Параметр | Live-режим | Анализ файла |
|----------|-----------|--------------|
| `windowSize` | 8 чанков (~12 с*) | неограничен |
| `confirmationCount` | 2 | 2 |
| `threshold` | 0.5 | 0.5 |
| Метод confidence | среднее top-3 | максимум |

\* При 50% перекрытии чанков (hopSize = 1.5 с) 8 чанков ≈ 12 секунд.

### Не-птичьи классы (фильтруются агрегатором)

```
Engine, Environmental, Fireworks, Gun,
Human vocal, Noise, Power tools, Siren,
Apis mellifera (медоносная пчела)
```

---

## 8. Потокобезопасность и параллелизм

| Компонент | Thread-safe? | Стратегия |
|-----------|-------------|-----------|
| `MappedByteBuffer` (модель) | Да | READ_ONLY mmap, shared между Interpreter'ами |
| `labels: List<Pair>` | Да | Immutable, shared |
| `Interpreter` (TFLite) | **Нет** | Отдельный экземпляр на каждый поток |
| `AudioChunkProcessor` | Да* | BandpassFilter.process() не хранит состояние между вызовами |
| `DetectionAggregator` | **Нет** | Mutable state (sliding window) |

\* AudioChunkProcessor безопасен для вызова из одного потока. BandpassFilter сбрасывает z1/z2 при каждом вызове `process()`, но сам вызов не атомарен.

Для параллельного инференса: создать N экземпляров `BirdNetV24Classifier`, каждый со своим `Interpreter`, но с общим `MappedByteBuffer` и `labels`.

---

## 9. Требования к производительности

| Метрика | Значение |
|---------|----------|
| Инференс (аудиомодель) | 100-300 мс/чанк (зависит от устройства) |
| Пре-процессинг | 3-5 мс/чанк |
| RAM (модели) | ~55 МБ (25 audio + 29 meta + 1 labels) |
| RAM (один Interpreter) | ~40 МБ (внутренние буферы) |
| Задержка до первого результата | ~3.5 с (запись чанка + инференс) |
| APK размер (модели) | ~54 МБ (сжимаются в APK) |
